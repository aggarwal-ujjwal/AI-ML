{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgU9U+TNRusxpFOGFZV1mO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aggarwal-ujjwal/AI-ML/blob/main/Deep_Q_Learning_for_Lunar_Landing_Handwritten_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://gymnasium.farama.org/environments/box2d/lunar_lander/"
      ],
      "metadata": {
        "id": "L6G2Xicn4vLM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSwK-mUKuwk-",
        "outputId": "6918636d-2ab3-4dda-f742-f89c89047309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "\u001b[33mWARNING: gymnasium 1.2.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 3s (414 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 126435 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Downloading swig-4.3.1.post0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.1.post0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp312-cp312-linux_x86_64.whl size=2381959 sha256=8dd6afca42db971c3f64cac5a859fddf7806ca4ba8931d2eb5b4f77a5e901aa9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/e9/60/774da0bcd07f7dc7761a8590fa2d065e4069568e78dcdc3318\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: swig, box2d-py\n",
            "Successfully installed box2d-py-2.3.5 swig-4.3.1.post0\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install \"gymnasium[atari, accept-rom-license]\"\n",
        "!apt-get install -y swig\n",
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "from collections import deque, namedtuple\n",
        "\n"
      ],
      "metadata": {
        "id": "fewR5ke6v6Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the NN"
      ],
      "metadata": {
        "id": "N33I3_uwzK7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module): #inheritance\n",
        "  def __init__(self, input_size, action_size, seed = 42): #you can remove seed from here\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.seed = torch.manual_seed(seed)\n",
        "    self.fc1 = nn.Linear(input_size, 64) #64 has to be calculated with expermentation\n",
        "    self.fc2 = nn.Linear(64,64)\n",
        "    self.fc3 = nn.Linear(64, action_size) #ends with 4 possible actions\n",
        "  #noob way\n",
        "  # def forward(self, state):\n",
        "  #   x = self.fc1(state)\n",
        "  #   x = F.relu(x)\n",
        "  #   x = self.fc2(x)\n",
        "  #   x = F.relu(x)\n",
        "  #   return self.fc3(x)\n",
        "\n",
        "  #better way\n",
        "  def forward(self, input): #input vector with 8 values like- ([0.5, -0.2, 1.0, 0.8])\n",
        "    \"\"\" # fc1(state): [8] -> [64] (linear transformation + bias)\n",
        "        # F.relu(): applies ReLU activation (max(0, x))\n",
        "        # x shape: [64] with all negative values clipped to 0\"\"\"\n",
        "    x = F.relu(self.fc1(input))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    actions = self.fc3(x)\n",
        "    return actions\n"
      ],
      "metadata": {
        "id": "hgslDDFQzKLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example for understanding - not to be used anywhere\n",
        "x = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])\n",
        "fc = nn.Linear(10, 64)\n",
        "output = fc(x)\n",
        "print(output)\n",
        "print(x.shape, output.shape)\n",
        "#Transforms input features into a higher-dimensional representation (10 → 64), allowing the network to learn more complex patterns."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlmD3tcJ71tX",
        "outputId": "95ea6328-5520-41ce-ca95-240b112d537f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.9912e-01, -3.4230e+00,  3.5476e+00,  2.2314e+00, -5.6016e+00,\n",
            "         2.5683e+00,  1.2996e+00, -2.8921e+00, -2.7405e+00, -2.0260e+00,\n",
            "         6.8871e+00, -3.4501e+00, -1.0745e+01, -2.0268e+00,  1.1376e+00,\n",
            "        -4.9283e-01,  4.7010e-01,  2.5421e+00, -1.6787e+00, -4.8147e+00,\n",
            "        -9.8752e-01, -9.9501e+00, -9.3120e+00,  1.4174e+00,  4.7613e+00,\n",
            "         1.2533e+00,  3.4996e+00, -2.8903e+00,  1.8413e+00,  3.6027e-01,\n",
            "        -1.9338e+00, -3.8423e+00,  1.9923e+00, -2.8707e+00,  1.1167e+00,\n",
            "         3.4304e+00,  2.0469e+00,  1.6896e+00, -1.6622e+00, -4.7463e-01,\n",
            "         3.0907e+00,  1.1544e+00,  2.5109e+00, -1.3669e+00, -2.1406e-01,\n",
            "        -3.3151e+00, -2.3495e+00, -2.3412e+00,  3.0829e+00,  5.7850e+00,\n",
            "         4.1797e+00,  5.5170e+00, -5.9128e+00,  4.0458e+00, -4.6105e+00,\n",
            "        -2.9455e+00,  3.3453e+00,  1.0292e-02, -6.8615e+00,  2.3503e+00,\n",
            "        -4.5343e+00,  1.1474e+00,  2.4058e+00, -1.1361e+00],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([10]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kJSVKcoe4t90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the NN\n"
      ],
      "metadata": {
        "id": "9rQbYguzBhU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make('LunarLander-v3') # will get it from the documentation\n",
        "print(env.action_space) #action - moving in 4 directions\n",
        "print(env.observation_space) #input - 8 values\n",
        "\n",
        "input_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "\n",
        "print(input_size, action_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EIaTc9HBl7c",
        "outputId": "4db02ed3-44f2-458f-dfa8-daa229a96f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(4)\n",
            "Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
            "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
            "  1.         1.       ], (8,), float32)\n",
            "8 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing the hyperparameters"
      ],
      "metadata": {
        "id": "okS5ElZ4E5Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 5e-4 #learning_rate = 5/10000 but this is the standard writing format\n",
        "minibatch_size = 100\n",
        "discount_factor = 0.99\n",
        "replay_buffer_size = int(1e5)\n",
        "interpolation_parameter = 1e-3 #Also known TAU"
      ],
      "metadata": {
        "id": "8Cn3souzDgjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning_rate = 5e-4\n",
        "\n",
        "What: Controls how big steps the neural network takes when updating weights\n",
        "\n",
        "Purpose: Too high = unstable learning, too low = slow learning\n",
        "\n",
        "5e-4: A good middle ground for most deep learning tasks\n",
        "\n",
        "minibatch_size = 100\n",
        "\n",
        "What: Number of experiences processed together in one training step\n",
        "\n",
        "Purpose: Balances training stability vs computational efficiency\n",
        "\n",
        "100: Good compromise between noise reduction and memory usage\n",
        "\n",
        "discount_factor = 0.99\n",
        "\n",
        "What: How much future rewards matter compared to immediate rewards\n",
        "\n",
        "Purpose: 0 = only care about immediate reward, 1 = future rewards matter equally\n",
        "0.99: Values future rewards highly but slightly less than immediate ones\n",
        "\n",
        "replay_buffer_size = int(1e5)\n",
        "\n",
        "What: Maximum number of past experiences stored in memory\n",
        "\n",
        "Purpose: Allows agent to learn from diverse past experiences, not just recent ones\n",
        "\n",
        "100,000: Large enough for good diversity, small enough to fit in memory\n",
        "\n",
        "interpolation_parameter = 1e-3 (tau)\n",
        "\n",
        "What: How quickly the target network updates toward the main network\n",
        "\n",
        "Purpose: Stabilizes training by slowly updating the target used for loss calculation\n",
        "\n",
        "0.001: Very slow updates = more stable training (common in DQN/DDPG)\n",
        "\n",
        "These are typical Deep Q-Network (DQN) or Deep Deterministic Policy Gradient (DDPG) hyperparameters for reinforcement learning.\n",
        "\n"
      ],
      "metadata": {
        "id": "myQtIWBQHMup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ReplayMemory** implements an experience replay buffer that stores and samples past experiences to train a reinforcement learning agent more effectively."
      ],
      "metadata": {
        "id": "ywfXGuANHAbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayMemory():\n",
        "  def __init__(self, capacity):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.capacity = capacity\n",
        "    self.memory = []\n",
        "\n",
        "  def push(self, event):\n",
        "    self.memory.append(event)\n",
        "    if len(self.memory) > len(self.capacity):\n",
        "      del self.memory[0]\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    experiences = random.sample(self.memory, k=batch_size)\n",
        "    states = torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float().to(self.device)\n",
        "    actions = torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).float().to(self.device)\n",
        "    rewards = torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float().to(self.device)\n",
        "    next_states = torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None])).float().to(self.device)\n",
        "    dones = torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n",
        "    return (states, actions, rewards, next_states, dones)\n"
      ],
      "metadata": {
        "id": "iVppytmPGdVS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[e[0] for e in experiences] - extracts state (index 0) from each experience\n",
        "\n",
        "np.vstack() - stacks arrays vertically into a batch\n",
        "\n",
        "torch.from_numpy() - converts NumPy array to PyTorch tensor\n",
        "\n",
        ".float() - ensures float32 data type\n",
        "\n",
        ".to(self.device) - moves tensor to GPU/CPU\n",
        "\n",
        "\n",
        "Each tuple: (state, action, reward, next_state, done)\n",
        "\n",
        "Eg.\n",
        "self.memory = [\n",
        "    (np.array([0.1, 0.2, 0.05, 0.1]), 0, 1.0, np.array([0.15, 0.25, 0.06, 0.12]), False),\n",
        "    (np.array([0.15, 0.25, 0.06, 0.12]), 1, 1.0, np.array([0.12, 0.22, 0.04, 0.08]), False),\n",
        "    (np.array([0.12, 0.22, 0.04, 0.08]), 0, 1.0, np.array([0.18, 0.28, 0.07, 0.14]), False),\n",
        "    # ... more experiences\n",
        "]\n",
        "\n",
        "batch_size = 2\n",
        "experiences = random.sample(self.memory, k=2)\n",
        "# Result: [(experience_1), (experience_3)]\n",
        "\n",
        "[\n",
        "    np.array([0.1, 0.2, 0.05, 0.1]),    # from experience_1\n",
        "    np.array([0.12, 0.22, 0.04, 0.08])  # from experience_3\n",
        "]\n",
        "\n",
        "np.vstack([...])\n",
        "\n",
        "np.array([\n",
        "    [0.1,  0.2,  0.05, 0.1 ],   # batch item 0\n",
        "    [0.12, 0.22, 0.04, 0.08]    # batch item 1\n",
        "])\n",
        "\n",
        "states = tensor([\n",
        "    [0.1000, 0.2000, 0.0500, 0.1000],\n",
        "    [0.1200, 0.2200, 0.0400, 0.0800]\n",
        "], device='cuda:0')  # Shape: torch.Size([2, 4])\n",
        "\n",
        "Summary\n",
        "\n",
        "Input: List of experience tuples in memory\n",
        "\n",
        "Process: Random sample → Extract states → Stack → Convert to tensor\n",
        "\n",
        "Output: Batched tensor ready for neural network training"
      ],
      "metadata": {
        "id": "U9vZuBofN8IM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning: keyword only parameters"
      ],
      "metadata": {
        "id": "w8W6KyCPM9kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def sample(self, population, k, *, counts=None): Where it came from? I opened documentation of random.py\n",
        "#                              ^\n",
        "#                    Everything after * must be keyword-only\n",
        "\n",
        "# Why use keyword-only parameters?\n",
        "# Clarity: Forces explicit naming of optional parameters\n",
        "# API stability: Can add new parameters without breaking existing calls\n",
        "# Prevents errors: Avoids accidental positional argument mistakes\n",
        "def greet(name, *, greeting=\"Hello\"):\n",
        "    return f\"{greeting}, {name}!\"\n",
        "\n",
        "# Valid calls:\n",
        "greet(\"Alice\")                    # greeting uses default\n",
        "greet(\"Alice\", greeting=\"Hi\")     # keyword argument\n",
        "\n",
        "# Invalid call:\n",
        "greet(\"Alice\", \"Hi\")              # Error! greeting must be keyword\n",
        "\n",
        "def process_data(data, *, sort=False, reverse=False, limit=None):\n",
        "    # Implementation here\n",
        "    pass\n",
        "\n",
        "# Valid calls:\n",
        "process_data([1, 2, 3])\n",
        "process_data([1, 2, 3], sort=True)\n",
        "process_data([1, 2, 3], sort=True, reverse=True, limit=10)\n",
        "\n",
        "# Invalid calls:\n",
        "process_data([1, 2, 3], True)           # Error!\n",
        "process_data([1, 2, 3], True, False)    # Error!\n"
      ],
      "metadata": {
        "id": "1tNTMTpLHb6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}